{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kegeHnEA48_O",
        "outputId": "cc2d45c3-5f74-44a1-b17b-ebfb59cac363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Training DNN on MNIST ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMciyB7KcRNR",
        "outputId": "d11ac44f-4042-4d08-d784-7847091fe49c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training DNN on MNIST ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess: flatten and normalize\n",
        "x_train_dnn = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
        "x_test_dnn = x_test.reshape(-1, 784).astype('float32') / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-nu9AeQcXoG",
        "outputId": "e2eebc0a-6f53-49e3-8407-276a5a07b489"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build DNN model\n",
        "dnn_model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "dnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGINpEemhxlb",
        "outputId": "51f1c03c-d48e-4d00-844f-31fe0d746753"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_history = dnn_model.fit(\n",
        "    x_train_dnn, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "dnn_loss, dnn_acc = dnn_model.evaluate(x_test_dnn, y_test, verbose=0)\n",
        "print(f\"DNN Test Accuracy: {dnn_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpTJUISph2gZ",
        "outputId": "38b6ff77-7662-4e15-8a34-0d90956fe2dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.7181 - val_accuracy: 0.9635 - val_loss: 0.1337\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.1935 - val_accuracy: 0.9715 - val_loss: 0.0992\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1314 - val_accuracy: 0.9750 - val_loss: 0.0857\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.1029 - val_accuracy: 0.9762 - val_loss: 0.0767\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0889 - val_accuracy: 0.9795 - val_loss: 0.0715\n",
            "DNN Test Accuracy: 0.9740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Training CNN on MNIST ===\")\n",
        "\n",
        "# Preprocess: add channel dimension\n",
        "x_train_cnn = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test_cnn = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Build CNN model\n",
        "cnn_model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztx93x_niKIh",
        "outputId": "6f6e63cc-1b27-4795-f317-7e89caa8f117"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training CNN on MNIST ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "cnn_history = cnn_model.fit(\n",
        "    x_train_cnn, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "cnn_loss, cnn_acc = cnn_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
        "print(f\"CNN Test Accuracy: {cnn_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RATG5rmTiMhu",
        "outputId": "4b4c39ac-33f0-4f3e-e44f-3f4a42741d68"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.8489 - loss: 0.5377 - val_accuracy: 0.9780 - val_loss: 0.0725\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.9790 - loss: 0.0688 - val_accuracy: 0.9842 - val_loss: 0.0535\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.9863 - loss: 0.0463 - val_accuracy: 0.9830 - val_loss: 0.0549\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.9879 - loss: 0.0402 - val_accuracy: 0.9895 - val_loss: 0.0367\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.9913 - loss: 0.0281 - val_accuracy: 0.9897 - val_loss: 0.0363\n",
            "CNN Test Accuracy: 0.9898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained CNN model\n",
        "cnn_model.save(\"mnist_cnn.h5\")\n",
        "print(\"Saved CNN model to mnist_cnn.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTNrwozTjilU",
        "outputId": "996a8fe0-648f-4513-85dc-8dd669647134"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved CNN model to mnist_cnn.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model(\"mnist_cnn.h5\")\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdY2uulttWeu",
        "outputId": "f6b4b255-cbc0-4192-873c-96ccdb7afc96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np    #not using\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def preprocess_digit_image(path):\n",
        "    # Load as grayscale and resize to 28x28\n",
        "    img = load_img(path, color_mode='grayscale', target_size=(28, 28))\n",
        "\n",
        "    # Convert to numpy array (28, 28, 1)\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Normalize values to 0–1\n",
        "    img_array = img_array.astype('float32') / 255.0\n",
        "\n",
        "    return img_array\n"
      ],
      "metadata": {
        "id": "3lFB84i-0cZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_digit_image(path, thresh=200, pad=10):\n",
        "    # 1) Load original image as grayscale\n",
        "    img = Image.open(path).convert(\"L\")   # 'L' = 8-bit grayscale\n",
        "    arr = np.array(img)\n",
        "\n",
        "    # 2) Create a mask for dark pixels (pen strokes are darker than background)\n",
        "    mask = arr < thresh  # tweak thresh (e.g. 180–220) if needed\n",
        "\n",
        "    # If nothing detected, just fall back to simple resize\n",
        "    if not mask.any():\n",
        "        img = img.resize((28, 28))\n",
        "        arr = np.array(img).astype(\"float32\") / 255.0\n",
        "        arr = 1.0 - arr  # invert\n",
        "        return arr.reshape(28, 28, 1)\n",
        "\n",
        "    # 3) Find bounding box of the digit\n",
        "    ys, xs = np.where(mask)\n",
        "    x_min, x_max = xs.min(), xs.max()\n",
        "    y_min, y_max = ys.min(), ys.max()\n",
        "\n",
        "    # 4) Add some padding around the digit\n",
        "    x_min = max(x_min - pad, 0)\n",
        "    y_min = max(y_min - pad, 0)\n",
        "    x_max = min(x_max + pad, arr.shape[1] - 1)\n",
        "    y_max = min(y_max + pad, arr.shape[0] - 1)\n",
        "\n",
        "    # 5) Crop to this bounding box\n",
        "    crop = img.crop((x_min, y_min, x_max + 1, y_max + 1))\n",
        "\n",
        "    # 6) Resize to 28×28 like MNIST\n",
        "    crop = crop.resize((28, 28))\n",
        "\n",
        "    # 7) Convert to array, normalize, and invert so digit is bright on dark\n",
        "    arr = np.array(crop).astype(\"float32\") / 255.0\n",
        "    arr = 1.0 - arr  # invert: background ~0, digit ~1\n",
        "\n",
        "    # 8) Add channel dimension\n",
        "    arr = arr.reshape(28, 28, 1)\n",
        "    return arr\n",
        "\n"
      ],
      "metadata": {
        "id": "EPMaO3kGtf7W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageOps #not using yet\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def preprocess_digit_image(path, pad=20):\n",
        "    # Load image\n",
        "    img = Image.open(path).convert('L')  # grayscale\n",
        "\n",
        "    # Convert to numpy (0=black, 255=white)\n",
        "    arr = np.array(img)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 1. THRESHOLD → isolate digit stroke\n",
        "    # ---------------------------\n",
        "    _, thresh = cv2.threshold(arr, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # If digit is white on black → invert to black on white\n",
        "    if np.mean(thresh) < 128:\n",
        "        thresh = 255 - thresh\n",
        "\n",
        "    # ---------------------------\n",
        "    # 2. FIND BOUNDING BOX\n",
        "    # ---------------------------\n",
        "    ys, xs = np.where(thresh < 128)\n",
        "    if len(xs) == 0 or len(ys) == 0:\n",
        "        raise ValueError(\"Digit not detected\")\n",
        "\n",
        "    x_min, x_max = xs.min(), xs.max()\n",
        "    y_min, y_max = ys.min(), ys.max()\n",
        "\n",
        "    # Crop with padding\n",
        "    x_min = max(0, x_min - pad)\n",
        "    y_min = max(0, y_min - pad)\n",
        "    x_max = min(thresh.shape[1], x_max + pad)\n",
        "    y_max = min(thresh.shape[0], y_max + pad)\n",
        "\n",
        "    crop = thresh[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3. RESIZE to 28x28\n",
        "    # ---------------------------\n",
        "    crop_img = Image.fromarray(crop)\n",
        "    crop_img = crop_img.resize((28, 28), Image.LANCZOS)\n",
        "\n",
        "    # Normalize and invert (MNIST is white digit on black)\n",
        "    arr = np.array(crop_img).astype('float32') / 255.0\n",
        "    arr = 1.0 - arr   # final inversion for MNIST style\n",
        "\n",
        "    return arr.reshape(28, 28, 1)\n"
      ],
      "metadata": {
        "id": "VrUh0XwN12Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_digit(model, img_path):\n",
        "    img_array = preprocess_digit_image(img_path)   # (28, 28, 1)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # (1, 28, 28, 1)\n",
        "\n",
        "    preds = model.predict(img_array)\n",
        "    digit = np.argmax(preds[0])\n",
        "    confidence = np.max(preds[0])\n",
        "    return digit, confidence\n",
        "\n"
      ],
      "metadata": {
        "id": "mVgrQMvbtlzz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digit, conf = predict_digit(model, \"digit_recog.png\")\n",
        "print(\"Predicted digit:\", digit)\n",
        "print(\"Confidence:\", conf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJJgnxWqtogk",
        "outputId": "ad94754a-0efe-42ce-d034-7d46488a8431"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Predicted digit: 8\n",
            "Confidence: 0.6939078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit, conf = predict_digit(model, \"digit_recogno9.png\")\n",
        "print(\"Predicted digit:\", digit)\n",
        "print(\"Confidence:\", conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMxYV1w-uX5K",
        "outputId": "4d9e9651-6677-49e5-9f67-3be77abe602c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Predicted digit: 1\n",
            "Confidence: 0.16438176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit, conf = predict_digit(model, \"digitalrecogno1paint.png\")\n",
        "print(\"Predicted digit:\", digit)\n",
        "print(\"Confidence:\", conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwE7jlRva4U",
        "outputId": "b60e7cc8-386a-484f-c887-3c6a8b875057"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Predicted digit: 1\n",
            "Confidence: 0.76519954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proc = preprocess_digit_image(\"no2blackbg.png\")  # your current function\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(proc.squeeze(), cmap=\"gray\")\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "w3TOp_f_wDyr",
        "outputId": "613a546f-a7fc-4d10-893a-be711b14f762"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit, conf = predict_digit(model, \"No3written.png\")\n",
        "print(\"Predicted digit:\", digit)\n",
        "print(\"Confidence:\", conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fedMeYnbxUzO",
        "outputId": "db4fb9c9-eba9-4f14-c85c-bb181c160893"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted digit: 3\n",
            "Confidence: 0.6426052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit, conf = predict_digit(model, \"no2blackbg.png\")\n",
        "print(\"Predicted digit:\", digit)\n",
        "print(\"Confidence:\", conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt_nOkBNy4TJ",
        "outputId": "bb8df99a-341f-422f-fc5d-85ea0cb6f69a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Predicted digit: 0\n",
            "Confidence: 0.54138076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit, conf = predict_digit(model, \"no5hw.png\")\n",
        "print(\"Predicted digit:\", digit)\n",
        "print(\"Confidence:\", conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxw6pCH4zXi1",
        "outputId": "2871c2df-e7e7-4912-eb4f-581f09b021a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Predicted digit: 5\n",
            "Confidence: 0.67060804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CnHQfOGY0BYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}